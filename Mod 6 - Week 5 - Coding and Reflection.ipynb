{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36105857",
   "metadata": {},
   "source": [
    "# Week 5 Coding Homework + Reflection 5\n",
    "_Auto-generated on 2025-10-12 22:25._\n",
    "\n",
    "This notebook contains two parts:\n",
    "- **Part A (Coding):** Support Vector Machines (SVM) — kernels, regularization (`C`), and RBF `gamma`, with notes on class imbalance.\n",
    "- **Part B (Reflection 5):** Feedback loops & DAGs + a small simulation.\n",
    "\n",
    "> Replace file paths and dataset names as needed. Run cells top-to-bottom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports & setup ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, RocCurveDisplay, accuracy_score, f1_score\n",
    "\n",
    "# For DAG drawings without Graphviz dependency\n",
    "import networkx as nx\n",
    "\n",
    "# General display\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "print(\"Libraries loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7e4473",
   "metadata": {},
   "source": [
    "\n",
    "## Part A — Week 5 Coding (SVM)\n",
    "\n",
    "This section demonstrates:\n",
    "1. Baseline SVM with different **kernels** (linear vs. RBF).\n",
    "2. Effect of **`C`** (regularization strength) and **`gamma`** (RBF kernel width) on performance.\n",
    "3. Handling **class imbalance** (notes + `class_weight='balanced'`).\n",
    "\n",
    "> If you have a dataset (e.g., `ckd.csv`), set `CSV_PATH` below. Otherwise, a synthetic dataset will be generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load your dataset or generate a synthetic fallback ===\n",
    "CSV_PATH = \"ckd.csv\"   # Change to your real dataset path or keep as-is to use synthetic data\n",
    "TARGET_COL = \"target\"  # Change to your target column when using a real dataset\n",
    "\n",
    "def load_or_generate():\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_PATH)\n",
    "        assert TARGET_COL in df.columns, f\"TARGET_COL '{TARGET_COL}' not found in CSV.\"\n",
    "        X = df.drop(columns=[TARGET_COL]).select_dtypes(include=[np.number]).fillna(0).values\n",
    "        y = df[TARGET_COL].values\n",
    "        print(f\"Loaded dataset from {CSV_PATH} with shape {X.shape}\")\n",
    "        return X, y, \"real\"\n",
    "    except Exception as e:\n",
    "        print(\"Falling back to synthetic classification dataset (not CKD). Reason:\", e)\n",
    "        # Synthetic: two classes; some overlap to be non-trivial\n",
    "        rng = np.random.default_rng(42)\n",
    "        n = 1200\n",
    "        X1 = rng.normal(loc=[0,0], scale=[1.2,1.2], size=(n//2,2))\n",
    "        X2 = rng.normal(loc=[2.0,2.5], scale=[1.0,1.0], size=(n//2,2))\n",
    "        X = np.vstack([X1, X2])\n",
    "        y = np.array([0]*(n//2) + [1]*(n//2))\n",
    "        # Inject slight class imbalance\n",
    "        keep_idx = np.where(~((y==1) & (rng.random(n) < 0.15)))[0]\n",
    "        X, y = X[keep_idx], y[keep_idx]\n",
    "        print(\"Synthetic data shape:\", X.shape, \"Positive rate:\", y.mean().round(3))\n",
    "        return X, y, \"synthetic\"\n",
    "\n",
    "X, y, data_source = load_or_generate()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=0)\n",
    "print(\"Train/Test sizes:\", X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Baseline SVM: linear kernel ===\n",
    "pipe_linear = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(kernel=\"linear\", class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scores_linear = cross_val_score(pipe_linear, X_train, y_train, cv=cv, scoring=\"f1\")\n",
    "print(\"Linear SVM CV F1 (mean ± sd):\", scores_linear.mean().round(3), \"±\", scores_linear.std().round(3))\n",
    "\n",
    "pipe_linear.fit(X_train, y_train)\n",
    "y_pred_lin = pipe_linear.predict(X_test)\n",
    "print(\"\\nTest report (Linear):\\n\", classification_report(y_test, y_pred_lin, digits=3))\n",
    "print(\"Confusion matrix (Linear):\\n\", confusion_matrix(y_test, y_pred_lin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ef269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RBF SVM with grid over C and gamma ===\n",
    "pipe_rbf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(kernel=\"rbf\", class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"svm__C\": [0.1, 1, 10, 100],\n",
    "    \"svm__gamma\": [\"scale\", 0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe_rbf, param_grid=param_grid, cv=cv, scoring=\"f1\", n_jobs=None)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best params (RBF):\", grid.best_params_)\n",
    "print(\"Best CV F1:\", round(grid.best_score_, 3))\n",
    "\n",
    "best_rbf = grid.best_estimator_\n",
    "y_pred_rbf = best_rbf.predict(X_test)\n",
    "print(\"\\nTest report (RBF best):\\n\", classification_report(y_test, y_pred_rbf, digits=3))\n",
    "print(\"Confusion matrix (RBF best):\\n\", confusion_matrix(y_test, y_pred_rbf))\n",
    "\n",
    "# Single ROC curve display (binary)\n",
    "try:\n",
    "    RocCurveDisplay.from_estimator(best_rbf, X_test, y_test)\n",
    "    plt.title(\"ROC Curve — Best RBF SVM\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\"ROC plot skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559992a",
   "metadata": {},
   "source": [
    "\n",
    "### Conclusions (edit these after you run)\n",
    "- **Best kernel:** (Fill: linear vs RBF) — compare CV F1 means and test reports.\n",
    "- **Effect of `C`:** Higher `C` usually fits harder (lower regularization), can improve training but risk overfit.\n",
    "- **Effect of `gamma` (RBF):** Larger `gamma` makes decision boundary more wiggly (local); too large can overfit.\n",
    "- **Class imbalance:** We used `class_weight='balanced'`. You can also try resampling (SMOTE) or threshold tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b01657",
   "metadata": {},
   "source": [
    "\n",
    "## Part B — Reflection 5: Feedback Loops & DAGs\n",
    "We'll draw DAGs with **networkx** and **matplotlib** (no Graphviz dependency) and build the requested simulation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3827e093",
   "metadata": {},
   "source": [
    "\n",
    "### Q1. Negative Feedback Loop\n",
    "High **Body Temperature (T)** increases **Sweating (S)**; **Sweating** increases **Cooling (C)**; **Cooling** **reduces** **Body Temperature**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cfec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Draw DAG for negative feedback using networkx ===\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from([(\"T\", {\"label\":\"Body Temperature\"}),\n",
    "                  (\"S\", {\"label\":\"Sweating\"}),\n",
    "                  (\"C\", {\"label\":\"Cooling\"})])\n",
    "\n",
    "G.add_edges_from([(\"T\",\"S\"), (\"S\",\"C\"), (\"C\",\"T\")])\n",
    "\n",
    "pos = nx.circular_layout(G)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "nx.draw_networkx_nodes(G, pos)\n",
    "nx.draw_networkx_labels(G, pos, labels={n:d[\"label\"] for n,d in G.nodes(data=True)})\n",
    "nx.draw_networkx_edges(G, pos, arrows=True)\n",
    "\n",
    "# Edge labels with signs\n",
    "edge_labels = {(\"T\",\"S\"): \"+\", (\"S\",\"C\"): \"+\", (\"C\",\"T\"): \"–\"}\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Negative Feedback Loop (Rendered Acyclically via Process Node)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c0e414",
   "metadata": {},
   "source": [
    "\n",
    "### Q2. Positive Feedback Loop (example)\n",
    "Example: **Social Media Use (U)** and **Anxiety (A)** can amplify each other. To keep the diagram DAG-compliant, we can add a time-step or mediator (e.g., **Rumination (R)**):  \n",
    "`U → A → R → U`. Signs are positive on each edge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0d5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Draw a positive feedback example as a DAG with a mediator ===\n",
    "G2 = nx.DiGraph()\n",
    "G2.add_nodes_from([(\"U\", {\"label\":\"Social Media Use\"}),\n",
    "                   (\"A\", {\"label\":\"Anxiety\"}),\n",
    "                   (\"R\", {\"label\":\"Rumination\"})])\n",
    "G2.add_edges_from([(\"U\",\"A\"), (\"A\",\"R\"), (\"R\",\"U\")])\n",
    "\n",
    "pos2 = nx.circular_layout(G2)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "nx.draw_networkx_nodes(G2, pos2)\n",
    "nx.draw_networkx_labels(G2, pos2, labels={n:d[\"label\"] for n,d in G2.nodes(data=True)})\n",
    "nx.draw_networkx_edges(G2, pos2, arrows=True)\n",
    "nx.draw_networkx_edge_labels(G2, pos2, edge_labels={(\"U\",\"A\"): \"+\", (\"A\",\"R\"): \"+\", (\"R\",\"U\"): \"+\"})\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Positive Feedback (with Mediator to Keep Acyclic Drawing)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81cc5bd",
   "metadata": {},
   "source": [
    "\n",
    "### Q3. Lightning–Deer–Bears–Flowers\n",
    "**DAG relations:** Lightning frightens away deer and bears (reduces both) and increases flowers; bears eat deer (reduces deer); deer eat flowers (reduces flowers).  \n",
    "We'll simulate data with noise and show a backdoor path (Lightning confounds Deer–Flowers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0030119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Simulation for Q3 ===\n",
    "np.random.seed(42)\n",
    "n = 5000\n",
    "\n",
    "lightning = np.random.uniform(0, 1, n)\n",
    "bears = np.maximum(1 - lightning + np.random.normal(0, 0.2, n), 0)\n",
    "deer = np.maximum(1 - (0.5*bears + 0.7*lightning) + np.random.normal(0, 0.2, n), 0)\n",
    "flowers = np.minimum(lightning + np.random.normal(0, 0.2, n) - 0.4*deer, 1)\n",
    "\n",
    "df_sim = pd.DataFrame({'lightning': lightning, 'bears': bears, 'deer': deer, 'flowers': flowers})\n",
    "df_sim.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DAG drawing for Q3 ===\n",
    "G3 = nx.DiGraph()\n",
    "labels3 = {\n",
    "    \"L\": \"Lightning\",\n",
    "    \"B\": \"Bears\",\n",
    "    \"D\": \"Deer\",\n",
    "    \"F\": \"Flowers\"\n",
    "}\n",
    "G3.add_nodes_from([(k, {\"label\": v}) for k,v in labels3.items()])\n",
    "G3.add_edges_from([(\"L\",\"B\"), (\"L\",\"D\"), (\"L\",\"F\"),\n",
    "                   (\"B\",\"D\"),\n",
    "                   (\"D\",\"F\")])\n",
    "\n",
    "pos3 = nx.spring_layout(G3, seed=3)\n",
    "plt.figure(figsize=(6,5))\n",
    "nx.draw_networkx_nodes(G3, pos3)\n",
    "nx.draw_networkx_labels(G3, pos3, labels={n:d[\"label\"] for n,d in G3.nodes(data=True)})\n",
    "nx.draw_networkx_edges(G3, pos3, arrows=True)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"DAG: Lightning–Bears–Deer–Flowers\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531bb06",
   "metadata": {},
   "source": [
    "\n",
    "**Backdoor path (Deer → Flowers):** Lightning is a **confounder** because it affects both deer and flowers. The backdoor path is `Deer ← Lightning → Flowers`. Controlling for lightning blocks this path when estimating the effect of deer on flowers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e43c0a",
   "metadata": {},
   "source": [
    "\n",
    "### Q4. Original DAG with Confounder and Collider\n",
    "**Nodes:** Education (X), Income (Y), Parental Support (C), Work Stress (W), Personality (P).  \n",
    "**Edges:** C → X, C → Y, X → Y, X → W, P → W.  \n",
    "- **Treatment-like (X):** Education  \n",
    "- **Outcome-like (Y):** Income  \n",
    "- **Confounder:** Parental Support (C)  \n",
    "- **Collider:** Work Stress (W) (has incoming arrows from X and P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DAG drawing for Q4 ===\n",
    "G4 = nx.DiGraph()\n",
    "labels4 = {\"X\":\"Education (X)\", \"Y\":\"Income (Y)\", \"C\":\"Parental Support (C)\", \"W\":\"Work Stress (W)\", \"P\":\"Personality (P)\"}\n",
    "G4.add_nodes_from([(k, {\"label\": v}) for k,v in labels4.items()])\n",
    "\n",
    "G4.add_edges_from([(\"C\",\"X\"), (\"C\",\"Y\"), (\"X\",\"Y\"), (\"X\",\"W\"), (\"P\",\"W\")])\n",
    "\n",
    "pos4 = nx.spring_layout(G4, seed=7)\n",
    "plt.figure(figsize=(7,5))\n",
    "nx.draw_networkx_nodes(G4, pos4)\n",
    "nx.draw_networkx_labels(G4, pos4, labels={n:d[\"label\"] for n,d in G4.nodes(data=True)})\n",
    "nx.draw_networkx_edges(G4, pos4, arrows=True)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original DAG with Confounder (C) and Collider (W)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
